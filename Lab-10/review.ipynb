{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ID-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlook_Overcast (entropy = 0.940), samples = 14\n",
      "Left:\n",
      "  Leaf node, class distribution: [0 4]\n",
      "Right:\n",
      "  Humidity (entropy = 1.000), samples = 10\n",
      "  Left:\n",
      "    Outlook_Rain (entropy = 0.811), samples = 4\n",
      "    Left:\n",
      "      Leaf node, class distribution: [0 1]\n",
      "    Right:\n",
      "      Leaf node, class distribution: [3 0]\n",
      "  Right:\n",
      "    Wind (entropy = 0.918), samples = 6\n",
      "    Left:\n",
      "      Temp (entropy = 0.918), samples = 3\n",
      "      Left:\n",
      "        Leaf node, class distribution: [0 1]\n",
      "      Right:\n",
      "        Leaf node, class distribution: [2 0]\n",
      "    Right:\n",
      "      Leaf node, class distribution: [0 3]\n",
      "Predicted class for input [1, 0, 1, 0, 1, 0]: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "df = pd.read_csv('data.csv')\n",
    "df['Wind'] = df['Wind'].map({'Weak':0,'Strong':1})\n",
    "df['Decision'] = df['Decision'].map({'No':0,'Yes':1})\n",
    "df = pd.get_dummies(df,columns=['Outlook'])\n",
    "\n",
    "def convertTemp(val):\n",
    "    if val >= df['Temp'].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def convertHumidity(val):\n",
    "    if val >= df['Humidity'].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Temp'] = df['Temp'].apply(convertTemp)\n",
    "df['Humidity'] = df['Humidity'].apply(convertHumidity)\n",
    "df['Outlook_Overcast'] = df['Outlook_Overcast'].map({False:0,True:1})\n",
    "df['Outlook_Rain'] = df['Outlook_Rain'].map({False:0,True:1})\n",
    "df['Outlook_Sunny'] = df['Outlook_Sunny'].map({False:0,True:1})\n",
    "x = df.drop('Decision',axis=1).values\n",
    "y = df['Decision'].values\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self,feature=None,entropy=None,samples=None,value = None,left=None,right=None):\n",
    "        self.entropy = entropy\n",
    "        self.feature = feature\n",
    "        self.samples = samples\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "    \n",
    "    def is_leaf(self):\n",
    "        return self.left is None and self.right is None\n",
    "\n",
    "def compute_entropy(y):\n",
    "    entropy = 0\n",
    "    if len(y) > 0:\n",
    "        p1 = len(y[y == 1])/len(y)\n",
    "        if p1 not in (0,1):\n",
    "            entropy = -p1*np.log2(p1) - (1-p1)*np.log2(1-p1)\n",
    "    return entropy\n",
    "\n",
    "def split_dataset(x,node_indices,feature):\n",
    "    left_indices,right_indices = [],[]\n",
    "    for i in node_indices:\n",
    "        if x[i][feature] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "    return left_indices,right_indices\n",
    "\n",
    "def compute_information_gain(x,y,node_indices,feature):\n",
    "    left_indices,right_indices = split_dataset(x,node_indices,feature)\n",
    "    x_node,y_node = x[node_indices],y[node_indices]\n",
    "    x_left,y_left = x[left_indices],y[left_indices]\n",
    "    x_right,y_right = x[right_indices],y[right_indices]\n",
    "    node_entropy = compute_entropy(y_node)\n",
    "    left_entropy = compute_entropy(y_left)\n",
    "    right_entropy = compute_entropy(y_right)\n",
    "    w_left = len(x_left)/len(x)\n",
    "    w_right = len(x_right)/len(x)\n",
    "    weighted_entropy = w_left*left_entropy + w_right*right_entropy\n",
    "    info_gain =  node_entropy - weighted_entropy\n",
    "    return info_gain\n",
    "\n",
    "def get_best_feature_split(x,y,node_indices):\n",
    "    num_features = x.shape[1]\n",
    "    best_feature = None\n",
    "    max_info_gain = -np.inf \n",
    "    for feature in range(num_features):\n",
    "        info_gain = compute_information_gain(x,y,node_indices,feature)\n",
    "        if info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            best_feature = feature\n",
    "    return best_feature\n",
    "\n",
    "#Algo for build tree \n",
    "'''1.find the node entropy\n",
    "2.compute bincount of class label\n",
    "3.create obj of tree class \n",
    "4. check for stop condition where entropy is 0 or curr == max_depth or only a unique class label left \n",
    "5.compute best feature split and check if best feature exists \n",
    "6.split dataset with best feature \n",
    "7.if there exists left_subtree update node.left with recursive call similarly apply to the right\n",
    "8.return node'''\n",
    "\n",
    "def build_id3_tree(x,y,node_indices,current_depth,max_depth):\n",
    "    entropy = compute_entropy(y[node_indices])\n",
    "    values = np.bincount(y[node_indices],minlength=2)\n",
    "    node = TreeNode(entropy=entropy,samples=len(node_indices),value=values)\n",
    "    if current_depth == max_depth or entropy == 0 or len(np.unique(y[node_indices])) == 1:\n",
    "        return node\n",
    "    best_feature = get_best_feature_split(x,y,node_indices)\n",
    "    if best_feature is None:\n",
    "        return node\n",
    "    left_indices,right_indices = split_dataset(x,node_indices,best_feature)\n",
    "    node.feature = best_feature\n",
    "    if left_indices is not None:\n",
    "        node.left = build_id3_tree(x,y,left_indices,current_depth+1,max_depth)\n",
    "    if right_indices is not None:\n",
    "        node.right = build_id3_tree(x,y,right_indices,current_depth+1,max_depth)\n",
    "    return node\n",
    "\n",
    "#Algo for print_tree \n",
    "'''1.check if feature names is not none and also node.feature is not none assign the feature name\n",
    "2.check if we reached the leaf node print the depth(indent spacing) and class dist\n",
    "3.else print the feature_name, node.entropy and node.samples\n",
    "4.if left subtree is exists  print depth and recursively call print_tree function similarly do it for the right subtree '''\n",
    "\n",
    "\n",
    "def print_tree(node, depth=0, feature_names=None):\n",
    "    if feature_names is not None and node.feature is not None:\n",
    "        feature_name = feature_names[node.feature]\n",
    "    else:\n",
    "        feature_name = f\"Feature {node.feature}\"\n",
    "\n",
    "    if node.is_leaf():\n",
    "        print(f\"{'  ' * depth}Leaf node, class distribution: {node.value}\")\n",
    "    else:\n",
    "        print(f\"{'  ' * depth}{feature_name} (entropy = {node.entropy:.3f}), samples = {node.samples}\")\n",
    "\n",
    "    if node.left is not None:\n",
    "        print(f\"{'  ' * depth}Left:\")\n",
    "        print_tree(node.left, depth + 1, feature_names)\n",
    "    if node.right is not None:\n",
    "        print(f\"{'  ' * depth}Right:\")\n",
    "        print_tree(node.right, depth + 1, feature_names)\n",
    "\n",
    "def predict(root_node, sample):\n",
    "    while not root_node.is_leaf():\n",
    "        feature_index = root_node.feature\n",
    "        if sample[feature_index] == 1:\n",
    "            root_node = root_node.right\n",
    "        else:\n",
    "            return np.random.choice([0, 1])\n",
    "    return np.argmax(root_node.value)\n",
    "\n",
    "\n",
    "root_node = build_id3_tree(x,y,list(range(len(y))),current_depth=0,max_depth=6)\n",
    "feature_names = df.drop('Decision',axis=1).columns.tolist()\n",
    "print_tree(root_node,feature_names=feature_names)\n",
    "sample_input = [1, 0, 1, 0, 1, 0]\n",
    "y_pred = predict(root_node,sample_input)\n",
    "print(f\"Predicted class for input {sample_input}: {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature None (entropy = 0.940) , (samples = 14)\n",
      "Left:\n",
      "  Leaf Node, Class distrubution:[0 4]\n",
      "Right\n",
      " Feature None (entropy = 1.000) , (samples = 10)\n",
      " Left:\n",
      "  Feature None (entropy = 0.811) , (samples = 4)\n",
      "  Left:\n",
      "    Leaf Node, Class distrubution:[0 1]\n",
      "  Right\n",
      "    Leaf Node, Class distrubution:[3 0]\n",
      " Right\n",
      "  Feature None (entropy = 0.918) , (samples = 6)\n",
      "  Left:\n",
      "   Feature None (entropy = 0.918) , (samples = 3)\n",
      "   Left:\n",
      "     Leaf Node, Class distrubution:[0 1]\n",
      "   Right\n",
      "     Leaf Node, Class distrubution:[2 0]\n",
      "  Right\n",
      "    Leaf Node, Class distrubution:[0 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "df = pd.read_csv('data.csv')\n",
    "df\n",
    "df['Wind'] = df['Wind'].map({'Weak':0,'Strong':1})\n",
    "df['Decision'] = df['Decision'].map({'No':0,'Yes':1})\n",
    "df = pd.get_dummies(df,columns=['Outlook'])\n",
    "\n",
    "def convertTemp(val):\n",
    "    if val >= df['Temp'].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def convertHumidity(val):\n",
    "    if val >= df['Humidity'].mean():\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df['Temp'] = df['Temp'].apply(convertTemp)\n",
    "df['Humidity'] = df['Humidity'].apply(convertHumidity)\n",
    "df['Outlook_Overcast'] = df['Outlook_Overcast'].map({False:0,True:1})\n",
    "df['Outlook_Rain'] = df['Outlook_Rain'].map({False:0,True:1})\n",
    "df['Outlook_Sunny'] = df['Outlook_Sunny'].map({False:0,True:1})\n",
    "x = df.drop('Decision',axis=1).values\n",
    "y = df['Decision'].values\n",
    "\n",
    "class TreeNode:\n",
    "    def __init__(self,feature=None,entropy=None,value=None,left=None,right=None,samples=None):\n",
    "        self.entropy = entropy\n",
    "        self.value = value\n",
    "        self.feature = feature\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.samples = samples\n",
    "\n",
    "    def is_leaf(self):\n",
    "        return self.left is None and self.right is None\n",
    "    \n",
    "def compute_entropy(y):\n",
    "    entropy = 0\n",
    "    if len(y) > 0:\n",
    "        p1 = len(y[y == 1]) / len(y)\n",
    "        if p1 not in (0, 1):\n",
    "            entropy = -p1 * np.log2(p1) - (1 - p1) * np.log2(1 - p1)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def split_dataset(x,node_indices,feature):\n",
    "    left_indices,right_indices = [],[]\n",
    "    for i in node_indices:\n",
    "        if x[i][feature] == 1:\n",
    "            left_indices.append(i)\n",
    "        else:\n",
    "            right_indices.append(i)\n",
    "    return left_indices,right_indices\n",
    "\n",
    "def compute_information_gain(x,y,node_indices,feature):\n",
    "    left_indices,right_indices = split_dataset(x,node_indices,feature)\n",
    "    x_node,y_node = x[node_indices],y[node_indices]\n",
    "    x_left,y_left = x[left_indices],y[left_indices]\n",
    "    x_right,y_right = x[right_indices],y[right_indices]\n",
    "    node_entropy = compute_entropy(y_node)\n",
    "    left_entropy = compute_entropy(y_left)\n",
    "    right_entropy = compute_entropy(y_right)\n",
    "    w_left = len(x_left)/len(x)\n",
    "    w_right = len(x_right)/len(x)\n",
    "    weighted_entropy = w_left*left_entropy + w_right*right_entropy\n",
    "    info_gain = node_entropy - weighted_entropy\n",
    "    return info_gain\n",
    "\n",
    "def get_best_feature_split(x,y,node_indices):\n",
    "    num_features = x.shape[1]\n",
    "    max_info_gain = -np.inf\n",
    "    best_feature = None\n",
    "    for feature in range(num_features):\n",
    "        info_gain = compute_information_gain(x,y,node_indices,feature)\n",
    "        if info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            best_feature = feature\n",
    "    return best_feature\n",
    "\n",
    "\n",
    "\n",
    "def build_id3_tree(x,y,node_indices,current_depth,max_depth):\n",
    "    entropy = compute_entropy(y[node_indices])\n",
    "    value = np.bincount(y[node_indices],minlength=2)\n",
    "    node = TreeNode(entropy=entropy,samples=len(node_indices),value=value)\n",
    "    if current_depth == max_depth or entropy == 0 or len(np.unique(y[node_indices])) == 1:\n",
    "        return node \n",
    "    best_feature = get_best_feature_split(x,y,node_indices)\n",
    "    if best_feature is None:\n",
    "        return node\n",
    "    left_indices,right_indices = split_dataset(x,node_indices,best_feature)\n",
    "    if left_indices is not None:\n",
    "        node.left = build_id3_tree(x,y,left_indices,current_depth+1,max_depth)\n",
    "    if right_indices is not None:\n",
    "        node.right = build_id3_tree(x,y,right_indices,current_depth+1,max_depth)\n",
    "    return node \n",
    "\n",
    "def print_tree(node,depth=0,feature_names=None):\n",
    "    if feature_names is not None and node.feature is not None:\n",
    "        feature_name = feature_names[node.feature]\n",
    "    else:\n",
    "        feature_name = f\"Feature {node.feature}\"\n",
    "    \n",
    "    if node.is_leaf():\n",
    "        print(f\"{' '  * depth} Leaf Node, Class distrubution:{node.value}\")\n",
    "    else:\n",
    "        print(f\"{' ' * depth}{feature_name} (entropy = {node.entropy:.3f}) , (samples = {node.samples})\")\n",
    "    \n",
    "    if node.left is not None:\n",
    "        print(f\"{' '*depth}Left:\")\n",
    "        print_tree(node.left,depth+1,feature_names)\n",
    "    if node.right is not None:\n",
    "        print(f\"{' '*depth}Right\")\n",
    "        print_tree(node.right,depth+1,feature_names)\n",
    "\n",
    "root_node = build_id3_tree(x,y,list(range(len(y))),current_depth=0,max_depth=6)\n",
    "feature_names = df.drop('Decision',axis=1).columns.tolist()\n",
    "print_tree(root_node,feature_names=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algo for build tree \n",
    "'''1.find the node entropy\n",
    "2.compute bincount of class label\n",
    "3.create obj of tree class \n",
    "4. check for stop condition where entropy is 0 or curr == max_depth or only a unique class label left \n",
    "5.compute best feature split and check if best feature exists \n",
    "6.split dataset with best feature \n",
    "7.if there exists left_subtree update node.left with recursive call similarly apply to the right\n",
    "8.return node'''\n",
    "\n",
    "def build_id3_tree(x,y,node_indices,current_depth,max_depth):\n",
    "    entropy = compute_entropy(y[node_indices])\n",
    "    values = np.bincount(y[node_indices],minlength=2)\n",
    "    node = TreeNode(entropy=entropy,samples=len(node_indices),value=values)\n",
    "    if current_depth == max_depth or entropy == 0 or len(np.unique(y[node_indices])) == 1:\n",
    "        return node\n",
    "    best_feature = get_best_feature_split(x,y,node_indices)\n",
    "    if best_feature is None:\n",
    "        return node\n",
    "    left_indices,right_indices = split_dataset(x,node_indices,best_feature)\n",
    "    if left_indices is not None:\n",
    "        node.left = build_id3_tree(x,y,left_indices,current_depth + 1,max_depth)\n",
    "    if right_indices is not None:\n",
    "        node.right = build_id3_tree(x,y,right_indices,current_depth + 1,max_depth)\n",
    "    return node\n",
    "\n",
    "\n",
    "#Algo for print_tree \n",
    "'''1.check if feature names is not none and also node.feature is not none assign the feature name\n",
    "2.check if we reached the leaf node print the depth(indent spacing) and class dist\n",
    "3.else print the feature_name, node.entropy and node.samples\n",
    "4.if left subtree is exists print depth and recursively call print_tree function similarly do it for the right subtree '''\n",
    "\n",
    "\n",
    "def print_tree(node,depth=0,feature_names=None):\n",
    "    if feature_names is not None and node.feature is not None:\n",
    "        feature_name = feature_names[node.feature]\n",
    "    else:\n",
    "        feature_name = \n",
    "    if node.is_leaf():\n",
    "        print(f\"' '*{depth} Class disturbution: {node.value} \")\n",
    "    else:\n",
    "        print(f\"' '*{depth}{feature_name} (entropy:{node.entropy:.3f}) (samples:{node.samples:.3f})\")\n",
    "    \n",
    "    if node.left is not None:\n",
    "        print(f\"' '*{depth}Left:\")\n",
    "        print_tree(node.left,depth+1,feature_names)\n",
    "    if node.right is not None:\n",
    "        print(f\"' '*{depth}Right:\")\n",
    "        print_tree(node.right,depth+1,feature_names)\n",
    "\n",
    "\n",
    "def build_id3_tree(x,y,node_indices,current_depth,max_depth):\n",
    "    entropy = compute_entropy(y[node_indices])\n",
    "    values = np.bincount(y[node_indices],minlength=2)\n",
    "    node = TreeNode(entropy=entropy,samples=len(node_indices),value=values)\n",
    "    if current_depth == max_depth or entropy == 0 or len(np.unique(y[node_indices])) == 1:\n",
    "        return node\n",
    "    best_feature = get_best_feature_split(x,y,node_indices)\n",
    "    if best_feature is None:\n",
    "        return node \n",
    "    left_indices,right_indices = split_dataset(x,node_indices,best_feature)\n",
    "    if left_indices is not None:\n",
    "        node.left = build_id3_tree(x,y,left_indices,current_depth+1,max_depth)\n",
    "    if right_indices is not None:\n",
    "        node.right = build_id3_tree(x,y,right_indices,current_depth+1,max_depth)\n",
    "    return node\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
